# -*- coding: utf-8 -*-
"""CSE445_ModelRunOnHouse_4AllModels_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w-Ppgfl0LQFhOfElJnugtNfCEfS06D3S
"""

# Import fundamental packages
import os
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns

# Mount the Google Drive into Colab to use the drive files
from google.colab import drive
drive.mount('/content/drive')

# The location of the csv file in Google Drive
csv_location = './drive/MyDrive/Datasets/CSE445/house_4/'

sorted(os.listdir(csv_location))

dataframes = []
for filename in sorted(os.listdir(csv_location)):
  # if filename == 'channel_1.csv': continue
  dataframe = pd.read_csv(csv_location+'/'+filename)
  dataframe.columns = ['timestamp', 'load_consumption']
  dataframe["timestamp"] = pd.to_datetime(dataframe["timestamp"],unit='s')
  dataframe = dataframe.set_index("timestamp")
  dataframes.append(dataframe)

"""# Model: AutoARIMA"""

def calculate_r_squared(actual, predicted):
    mean_actual = np.mean(actual)
    ss_total = np.sum((actual - mean_actual) ** 2)
    ss_residual = np.sum((actual - predicted) ** 2)
    r_squared = 1 - (ss_residual / ss_total)
    return r_squared

def calculate_mean_absolute_error(actual, predicted):
    mae = np.mean(np.abs(actual - predicted))
    return mae

def calculate_mean_absolute_percentage_error(actual, predicted):
    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    return mape

def calculate_mean_squared_error(actual, predicted):
    mse = np.mean((actual - predicted) ** 2)
    return mse

def calculate_root_mean_squared_error(actual, predicted):
    rmse = np.sqrt(np.mean((actual - predicted) ** 2))
    return rmse

def calculate_normalized_root_mean_squared_error(actual, predicted):
    nrmse = np.sqrt(np.mean((actual - predicted) ** 2)) / (np.max(actual) - np.min(actual))
    return nrmse

def calculate_aic(training_data, predicted_data, num_params):
    residuals = predicted_data - training_data
    sse = np.sum(residuals**2)
    n = len(training_data)
    aic = n * np.log(sse/n) + 2 * num_params
    return aic

def calculate_bic(training_data, predicted_data, num_params):
    residuals = predicted_data - training_data
    sse = np.sum(residuals**2)
    n = len(training_data)
    bic = n * np.log(sse/n) + num_params * np.log(n)
    return bic

!pip install pmdarima

from pmdarima.arima import auto_arima

resample_rule='24H'
target_channel = 0
current_in_hand_data_working=(dataframes[target_channel][:int(len(dataframes[target_channel])*0.6)]).resample(resample_rule).mean()

# Train Test Split 80-20
data_to_train_on = current_in_hand_data_working[0:int(len(current_in_hand_data_working)*0.8)]
data_to_test_on = current_in_hand_data_working[int(len(current_in_hand_data_working)*0.8):]
print("Total training datapoints:", len(data_to_train_on))
print("Total testing datapoints:", len(data_to_test_on))

# Plot the training+testing figure
plt.plot(data_to_train_on.index, data_to_train_on['load_consumption'], color='blue', label='Training')
plt.plot(data_to_test_on.index, data_to_test_on['load_consumption'], color='red', label='Testing')
plt.title('Traing-Test Split with Sampling='+resample_rule)
plt.xlabel('Time Index')
plt.ylabel('Load Consumptions')
plt.legend()
plt.xticks(rotation=45)
plt.show()

# Get the y-values
y_train = np.nan_to_num(data_to_train_on.load_consumption.values, nan=0.0)
y_test = np.nan_to_num(data_to_test_on.load_consumption.values, nan=0.0)

# Run AutoArima
model = auto_arima(
    y_train, # Using full data, because the last results will be used for validation
    X=None,
    start_p=1,
    d=None,  # Must, in order to iterate over 'd' (number of differencing)
    start_q=1,
    max_p=5,
    max_d=5,
    max_q=5,
    start_P=1,
    D=None,
    start_Q=1,
    max_P=5,
    max_D=5,
    max_Q=5,
    max_order=200,
    m=1,
    seasonal=False,
    stationary=False,
    information_criterion='aic',
    alpha=0.05,
    test='adf',
    seasonal_test='ocsb',
    stepwise=True,
    n_jobs=1,
    start_params=None,
    trend=None,
    method='lbfgs',
    maxiter=50,
    offset_test_args=None,
    seasonal_test_args=None,
    suppress_warnings=True,
    error_action='trace',
    trace=True,
    random=False,
    random_state=None,
    n_fits=10,
    return_valid_fits=False,
    out_of_sample_size=0,
    scoring='mse',
    scoring_args=None,
    with_intercept="auto",
    sarimax_kwargs=None
)
print(model.summary())

forecasts = model.predict(len(y_test))

# Plot the training+testing=prediction figure
plt.plot(data_to_train_on.index, data_to_train_on['load_consumption'], color='blue', label='Training')
plt.plot(data_to_test_on.index, data_to_test_on['load_consumption'], color='red', label='Testing')
plt.plot(data_to_test_on.index, forecasts, color='green', label='Prediction')
plt.title('ARIMA: Traing-Test Split with Sampling='+resample_rule)
plt.xlabel('Time Index')
plt.ylabel('Load Consumptions')
plt.legend()
plt.xticks(rotation=45)
plt.show()

r_squared = calculate_r_squared(data_to_test_on['load_consumption'], forecasts)
mae = calculate_mean_absolute_error(data_to_test_on['load_consumption'], forecasts)
mape = calculate_mean_absolute_percentage_error(data_to_test_on['load_consumption'], forecasts)
mse = calculate_mean_squared_error(data_to_test_on['load_consumption'], forecasts)
rmse = calculate_root_mean_squared_error(data_to_test_on['load_consumption'], forecasts)
nrmse = calculate_normalized_root_mean_squared_error(data_to_test_on['load_consumption'], forecasts)

print("R-Squared:", format(r_squared, '.2f'))
print("Mean Absolute Error:", format(mae, '.4f'))
print("Mean Absolute Percentage Error:", format(mape, '.2f'))
print("Mean Squared Error:", format(mse, '.2f'))
print("Root Mean Squared Error:", format(rmse, '.2f'))
print("Normalized Root Mean Squared Error:", format(nrmse, '.2f'))


print()

print("", format(r_squared, '.2f'))
print("", format(mae, '.4f'))
print("", format(mape, '.2f'))
print("", format(mse, '.2f'))
print("", format(rmse, '.2f'))
print("", format(nrmse, '.2f'))

"""# Model: LSTM"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data

device = "cuda" if torch.cuda.is_available() else "cpu"
# device = "cpu"
print(f"Using {device} device")

resample_rule='1H'
target_channel = 0
current_in_hand_data_working=(dataframes[target_channel][:int(len(dataframes[target_channel])*0.6)]).resample(resample_rule).mean()
timeseries = current_in_hand_data_working['load_consumption'].values.reshape(-1, 1)

# train-test split for time series
train_size = int(len(timeseries) * 0.8)
test_size = len(timeseries) - train_size
train, test = timeseries[:train_size], timeseries[train_size:]

def create_dataset(dataset, lookback):
    X, y = [], []
    for i in range(len(dataset)-lookback):
        feature = dataset[i:i+lookback]
        target = dataset[i+1:i+lookback+1]
        X.append(feature)
        y.append(target)
    return torch.tensor(X).float(), torch.tensor(y).float()

lookback = 4
X_train, y_train = create_dataset(train, lookback=lookback)
X_test, y_test = create_dataset(test, lookback=lookback)

X_train = X_train.to(device)
y_train = y_train
X_test = X_test.to(device)
y_test = y_test

class RNNConfig(nn.Module):
    def __init__(self):
        super().__init__()
        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)
        self.linear = nn.Linear(50, 1)
    def forward(self, x):
        x, _ = self.lstm(x)
        x = self.linear(x)
        return x

model = RNNConfig().to(device)

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

optimizer = optim.Adam(model.parameters(),lr=0.0001)
loss_fn = nn.MSELoss()
loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)

n_epochs = 8000
for epoch in range(n_epochs):
    model.train()
    for X_batch, y_batch in loader:
        y_pred = model(X_batch.to(device))
        loss = loss_fn(y_pred, y_batch.to(device))
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    # Validation
    if epoch % 100 != 0:
        continue
    model.eval()
    with torch.no_grad():
        y_pred = model(X_train.to(device))
        train_rmse = np.sqrt(loss_fn(y_pred.cpu(), y_train.cpu()))
        y_pred = model(X_test)
        test_rmse = np.sqrt(loss_fn(y_pred.cpu(), y_test.cpu()))
    print("Epoch %d: train RMSE %.4f, test RMSE %.4f" % (epoch, train_rmse, test_rmse))

with torch.no_grad():
    # shift train predictions for plotting
    train_plot = np.ones_like(timeseries) * np.nan
    y_pred = model(X_train)
    y_pred = y_pred[:, -1, :]
    train_plot[lookback:train_size] = (model(X_train).cpu())[:, -1, :]
    # shift test predictions for plotting
    test_plot = np.ones_like(timeseries) * np.nan
    predx = model(X_test)
    test_plot[train_size+lookback:len(timeseries)] = (predx.cpu())[:, -1, :]
# plot

# Train Test Split 80-20
data_to_train_on = current_in_hand_data_working[0:train_size]
data_to_test_on = current_in_hand_data_working[train_size:]

# Find forecasted values
forecasts = test_plot.reshape(-1)
forecasts = forecasts[~np.isnan(forecasts)]
forecasts = np.concatenate((data_to_test_on['load_consumption'][:lookback], forecasts))

# Plot the training+testing=prediction figure
plt.plot(data_to_train_on.index, data_to_train_on['load_consumption'], color='blue', label='Training')
plt.plot(data_to_test_on.index, data_to_test_on['load_consumption'], color='red', label='Testing')
plt.plot(data_to_test_on.index, forecasts, color='green', label='Prediction')
plt.title('LSTM: Traing-Test Split with Sampling='+resample_rule)
plt.xlabel('Time Index')
plt.ylabel('Load Consumptions')
plt.legend()
plt.xticks(rotation=45)
plt.show()

r_squared = calculate_r_squared(data_to_test_on['load_consumption'], forecasts)
mae = calculate_mean_absolute_error(data_to_test_on['load_consumption'], forecasts)
mape = calculate_mean_absolute_percentage_error(data_to_test_on['load_consumption'], forecasts)
mse = calculate_mean_squared_error(data_to_test_on['load_consumption'], forecasts)
rmse = calculate_root_mean_squared_error(data_to_test_on['load_consumption'], forecasts)
nrmse = calculate_normalized_root_mean_squared_error(data_to_test_on['load_consumption'], forecasts)

print("R-Squared:", format(r_squared, '.2f'))
print("Mean Absolute Error:", format(mae, '.4f'))
print("Mean Absolute Percentage Error:", format(mape, '.2f'))
print("Mean Squared Error:", format(mse, '.2f'))
print("Root Mean Squared Error:", format(rmse, '.2f'))
print("Normalized Root Mean Squared Error:", format(nrmse, '.2f'))

print()

print("", format(r_squared, '.2f'))
print("", format(mae, '.4f'))
print("", format(mape, '.2f'))
print("", format(mse, '.2f'))
print("", format(rmse, '.2f'))
print("", format(nrmse, '.2f'))

"""# Model: XGBOOST"""

# forecast monthly births with xgboost
from numpy import asarray
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
from matplotlib import pyplot

# transform a time series dataset into a supervised learning dataset
def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
	n_vars = 1 if type(data) is list else data.shape[1]
	df = DataFrame(data)
	cols = list()
	# input sequence (t-n, ... t-1)
	for i in range(n_in, 0, -1):
		cols.append(df.shift(i))
	# forecast sequence (t, t+1, ... t+n)
	for i in range(0, n_out):
		cols.append(df.shift(-i))
	# put it all together
	agg = concat(cols, axis=1)
	# drop rows with NaN values
	if dropnan:
		agg.dropna(inplace=True)
	return agg.values

# split a univariate dataset into train/test sets
def train_test_split(data, n_test):
	return data[:-n_test, :], data[-n_test:, :]

# fit an xgboost model and make a one step prediction
def xgboost_forecast(train, testX):
	# transform list into array
	train = asarray(train)
	# split into input and output columns
	trainX, trainy = train[:, :-1], train[:, -1]
	# fit model
	model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)
	model.fit(trainX, trainy)
	# make a one-step prediction
	yhat = model.predict(asarray([testX]))
	return yhat[0]

# walk-forward validation for univariate data
def walk_forward_validation(data, n_test):
	predictions = list()
	# split dataset
	train, test = train_test_split(data, n_test)
	# seed history with training dataset
	history = [x for x in train]
	# step over each time-step in the test set
	for i in range(len(test)):
		# split test row into input and output columns
		testX, testy = test[i, :-1], test[i, -1]
		# fit model on history and make a prediction
		yhat = xgboost_forecast(history, testX)
		# store forecast in list of predictions
		predictions.append(yhat)
		# add actual observation to history for the next loop
		history.append(test[i])
		# summarize progress
		print('>expected=%.1f, predicted=%.1f' % (testy, yhat))
	# estimate prediction error
	error = mean_absolute_error(test[:, -1], predictions)
	return error, test[:, -1], predictions

resample_rule='1H'
target_channel = 0
current_in_hand_data_working=(dataframes[target_channel][:int(len(dataframes[target_channel])*0.6)]).resample(resample_rule).mean()

# Train Test Split 80-20
data_to_train_on = current_in_hand_data_working[0:int(len(current_in_hand_data_working)*0.8)]
data_to_test_on = current_in_hand_data_working[int(len(current_in_hand_data_working)*0.8):]
print("Total training datapoints:", len(data_to_train_on))
print("Total testing datapoints:", len(data_to_test_on))

# Get the y-values
y_train = np.nan_to_num(data_to_train_on.load_consumption.values, nan=0.0)
y_test = np.nan_to_num(data_to_test_on.load_consumption.values, nan=0.0)

# load the dataset
# transform the time series data into supervised learning
data = series_to_supervised(current_in_hand_data_working.values, n_in=6)
# evaluate
mae, y, yhat = walk_forward_validation(data, len(y_test))
print('MAE: %.3f' % mae)
# plot expected vs preducted
pyplot.plot(y, label='Expected')
pyplot.plot(yhat, label='Predicted')
pyplot.legend()
pyplot.show()

forecasts = yhat

# Plot the training+testing=prediction figure
plt.plot(data_to_train_on.index, data_to_train_on['load_consumption'], color='blue', label='Training')
plt.plot(data_to_test_on.index, data_to_test_on['load_consumption'], color='red', label='Testing')
plt.plot(data_to_test_on.index, forecasts, color='green', label='Prediction')
plt.title('XGBOOST: Traing-Test Split with Sampling='+resample_rule)
plt.xlabel('Time Index')
plt.ylabel('Load Consumptions')
plt.legend()
plt.xticks(rotation=45)
plt.show()

r_squared = calculate_r_squared(data_to_test_on['load_consumption'], forecasts)
mae = calculate_mean_absolute_error(data_to_test_on['load_consumption'], forecasts)
mape = calculate_mean_absolute_percentage_error(data_to_test_on['load_consumption'], forecasts)
mse = calculate_mean_squared_error(data_to_test_on['load_consumption'], forecasts)
rmse = calculate_root_mean_squared_error(data_to_test_on['load_consumption'], forecasts)
nrmse = calculate_normalized_root_mean_squared_error(data_to_test_on['load_consumption'], forecasts)

print("R-Squared:", format(r_squared, '.2f'))
print("Mean Absolute Error:", format(mae, '.4f'))
print("Mean Absolute Percentage Error:", format(mape, '.2f'))
print("Mean Squared Error:", format(mse, '.2f'))
print("Root Mean Squared Error:", format(rmse, '.2f'))
print("Normalized Root Mean Squared Error:", format(nrmse, '.2f'))

print()

print("", format(r_squared, '.2f'))
print("", format(mae, '.4f'))
print("", format(mape, '.2f'))
print("", format(mse, '.2f'))
print("", format(rmse, '.2f'))
print("", format(nrmse, '.2f'))

